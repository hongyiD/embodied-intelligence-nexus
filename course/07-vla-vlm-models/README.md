# 第七章：具身智能：VLA与VLM模型

- **作者**: Damon Li
- **日期**: 2026年2月4日

本章将深入探讨具身智能领域的前沿进展，特别是视觉-语言-动作 (Vision-Language-Action, VLA) 模型和视觉-语言模型 (Vision-Language Model, VLM) 在机器人控制中的应用。我们将涵盖Transformer、Diffusion Policy等核心技术，并介绍RT1/RT2、Octo、OpenVLA等具身智能的代表性模型。

## 章节目录

- [7.1 简介](./7.1-introduction.md)
- [7.2 Transformer与生成模型](./7.2-transformers-generative-models.md)
- [7.3 ACT与变体，Diffusion Policy](./7.3-act-variants-diffusion-policy.md)
- [7.4 VLM与LLM用于规划](./7.4-vlm-llm-for-planning.md)
- [7.5 VLA: RT1, RT2, Octo和OpenVLA](./7.5-vla-rt1-rt2-octo-openvla.md)
- [7.6 VLA: RDT, Pio和其他](./7.6-vla-rdt-pio-others.md)
- [7.7 数据集与基准](./7.7-datasets-benchmarks.md)
- [7.8 总结](./7.8-summary.md)
