# 7.7 数据集与基准

- **作者**: Damon Li
- **日期**: 2026年2月4日

## 1. 概述

高质量的数据集和可靠的基准测试是推动具身智能，特别是视觉-语言-动作 (VLA) 和视觉-语言模型 (VLM) 发展的关键。它们不仅为模型训练提供了丰富的经验，也为评估模型的性能、泛化能力和鲁棒性提供了标准化的方法。本节将介绍具身智能领域中几个重要的数据集和基准，包括 Minari、D4RL、Open X-Embodiment (OXE) 以及 Sim-to-Real 评估方法。

## 2. Minari 与 D4RL

### 2.1 Minari

**Minari** 是一个 Python 库，专门用于离线强化学习 (Offline Reinforcement Learning) 的研究 [1]。它提供了一个统一的接口来管理、存储和访问离线数据集，这些数据集通常包含由专家或次优策略收集的交互数据。Minari 的目标是促进离线 RL 算法的开发和比较，因为离线 RL 允许智能体从预先收集的数据中学习，而无需与真实环境进行昂贵的在线交互。

在 VLA/VLM 的背景下，Minari 可以用于组织和分发机器人演示数据集，这些数据集可以用于模仿学习或离线强化学习，从而训练 VLA 模型。

### 2.2 D4RL

**D4RL (Datasets for Deep Data-Driven Reinforcement Learning)** 是一个广泛使用的离线强化学习基准，它提供了一系列标准化的环境和数据集，用于训练和评估离线 RL 算法 [2]。D4RL 包含了来自各种任务（如机器人运动、操作、导航）的数据集，这些数据集通常由不同质量的策略（从随机策略到专家策略）生成。

**D4RL 的特点**：
-   **多样化的数据集**：包含来自 MuJoCo、Gym 等环境的多种任务数据集。
-   **不同质量的轨迹**：数据集中的轨迹质量各异，模拟了真实世界中数据收集的复杂性。
-   **标准化评估**：提供了一套标准的评估指标和流程，便于研究者比较不同算法的性能。

在 VLA/VLM 领域，D4RL 可以作为评估离线 VLA 策略性能的工具，特别是在需要从非专家演示中学习的任务中。

## 3. Open X-Embodiment Dataset (OXE)

**Open X-Embodiment (OXE) Dataset** 是目前规模最大、最全面的开源真实机器人数据集，由21个机构合作收集，涵盖了22种不同的机器人平台 [3]。OXE 旨在通过提供一个大规模、多样化的数据集，加速通用机器人学习和 VLA 模型的发展。

**OXE 的特点**：
-   **规模空前**：包含超过100万条真实机器人轨迹，涵盖了527种技能和160,266个任务 [4]。
-   **多机器人平台**：数据来自多种不同构型和传感器的机器人，促进了跨具身泛化 (Cross-Embodiment Generalization) 的研究。
-   **多样化的任务**：涵盖了从简单抓取到复杂操作的广泛任务，模拟了真实世界中机器人应用的复杂性。
-   **统一数据格式**：采用 RLDS (Reinforcement Learning Dataset) 格式，便于数据的存储、管理和共享。

OXE 数据集是训练如 Octo 等通用 VLA 模型的基础，它使得模型能够从海量真实世界经验中学习，从而提高其泛化能力和鲁棒性。

## 4. 其他数据集与基准

除了上述大型数据集，还有一些其他的基准和数据集在 VLA/VLM 研究中发挥作用：

-   **VLABench**：一个大规模的基准测试，旨在公平评估 VLA、具身智能体和 VLM 的性能。它提供了100个精心设计的任务类别，并具有强大的随机化能力，用于测试模型的泛化能力 [5]。
-   **VLA-Risk**：一个专门用于评估 VLA 模型物理鲁棒性的新基准，关注模型在面对物理风险时的表现 [6]。
-   **特定任务数据集**：许多研究团队会针对特定任务（如灵巧操作、双臂协作）收集小规模、高质量的数据集，用于验证其提出的新算法。

## 5. Sim-to-Real 迁移与评估

**Sim-to-Real (仿真到真实)** 迁移是机器人学习中的一个核心挑战，也是评估 VLA/VLM 模型实用性的重要环节。由于在真实世界中收集数据和训练机器人成本高昂且耗时，研究者通常会在仿真环境中训练模型，然后将其部署到真实机器人上 [7]。

**Sim-to-Real 迁移的挑战**：
-   **仿真与真实世界的差异 (Reality Gap)**：仿真环境与真实世界之间存在物理参数、传感器噪声、动力学模型等方面的差异，这可能导致在仿真中表现良好的策略在真实世界中失效。
-   **数据分布不匹配**：仿真数据和真实数据之间可能存在分布差异，影响模型的泛化能力。

**Sim-to-Real 评估方法**：
-   **领域随机化 (Domain Randomization)**：在仿真环境中随机化各种参数（如物体纹理、光照、摩擦系数），以期望模型能够学习到对这些变化鲁棒的策略，从而更好地迁移到真实世界。
-   **领域适应 (Domain Adaptation)**：利用少量真实世界数据来微调在仿真中训练的模型，以弥合仿真与真实世界之间的差距。
-   **物理引擎**：使用高保真度的物理引擎来模拟真实世界的物理交互，减少 Reality Gap。

在 VLA/VLM 领域，Sim-to-Real 迁移的成功意味着模型不仅能够理解抽象的指令，还能在复杂的物理世界中可靠地执行任务。因此，在数据集和基准测试中，对 Sim-to-Real 性能的评估变得越来越重要。

## 6. 代码示例 (概念性数据集加载与预处理)

以下是一个概念性的 Python 代码示例，展示了如何加载和预处理一个简化的机器人轨迹数据集。在实际的 VLA/VLM 训练中，数据集的加载和预处理会更加复杂，涉及多模态数据的同步、特征提取和数据增强。

```python
import torch
import numpy as np
from torch.utils.data import Dataset, DataLoader

# 模拟一个简单的机器人轨迹数据集
class ConceptualRobotDataset(Dataset):
    def __init__(self, num_samples=100, seq_len=10, obs_dim=64, action_dim=7):
        self.num_samples = num_samples
        self.seq_len = seq_len
        self.obs_dim = obs_dim
        self.action_dim = action_dim
        
        self.data = []
        for _ in range(num_samples):
            # 模拟视觉观测序列 (例如，图像特征)
            visual_obs = torch.randn(seq_len, obs_dim)
            # 模拟语言指令 (例如，嵌入向量)
            language_instruction = torch.randn(lang_dim)
            # 模拟动作序列 (例如，关节速度)
            actions = torch.randn(seq_len, action_dim)
            self.data.append({
                'visual_obs': visual_obs,
                'language_instruction': language_instruction,
                'actions': actions
            })

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        sample = self.data[idx]
        return sample['visual_obs'], sample['language_instruction'], sample['actions']

if __name__ == "__main__":
    lang_dim = 768 # 假设语言嵌入维度
    
    # 创建概念性数据集
    dataset = ConceptualRobotDataset(num_samples=1000, seq_len=15, obs_dim=128, action_dim=7)
    
    # 创建数据加载器
    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)
    
    print("--- 概念性机器人数据集加载与预处理 ---")
    for i, (visual_obs_batch, lang_inst_batch, actions_batch) in enumerate(dataloader):
        print(f"Batch {i+1}:")
        print(f"  视觉观测批次形状: {visual_obs_batch.shape}") # (batch_size, seq_len, obs_dim)
        print(f"  语言指令批次形状: {lang_inst_batch.shape}") # (batch_size, lang_dim)
        print(f"  动作批次形状: {actions_batch.shape}")     # (batch_size, seq_len, action_dim)
        
        if i >= 2: # 只打印前3个批次
            break
    
    print("\n数据集加载与预处理完成。")
```

## 7. 参考资料

- [1] Minari. (n.d.). *Minari: A Python library for offline reinforcement learning*. [URL](https://minari.farama.org/)
- [2] D4RL. (n.d.). *D4RL: Datasets for Deep Data-Driven Reinforcement Learning*. [URL](https://github.com/Farama-Foundation/D4RL)
- [3] Google DeepMind. (2023). *Open X-Embodiment: Robotic Learning Datasets and RT-X Models*. [URL](https://robotics-transformer-x.github.io/)
- [4] Brohan, A., et al. (2023). Open X-Embodiment: Robotic Learning Datasets and RT-X Models. *arXiv preprint arXiv:2310.08864*.
- [5] VLABench. (n.d.). *VLABench: A Large-Scale Benchmark for Language-Conditioned Robotics Manipulation with Long-Horizon Tasks*. [URL](https://vlabench.github.io/)
- [6] VLA-Risk. (n.d.). *VLA-Risk: Benchmarking Vision-Language-Action Models for Physical Robustness*. [URL](https://openreview.net/forum?id=31EjDFwFEe)
- [7] Tobin, J., et al. (2017). Domain Randomization for Transferring Deep Neural Networks from Simulation to the Real World. *IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)*.
