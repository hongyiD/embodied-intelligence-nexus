# 第六章：强化学习方法

- **作者**: Damon Li
- **日期**: 2026年2月4日

## 1. 强化学习简介
### 1.1 MDP和POMDP
[内容占位符]
### 1.2 RL Overview
[内容占位符]
### 1.3 Value Function
[内容占位符]
### 1.4 Value Iteration
[内容占位符]
### 1.5 Policy Iteration
[内容占位符]
### 1.6 RL Algorithms
[内容占位符]

## 2. Q Learning
### 2.1 Value based Method
[内容占位符]
### 2.2 Fitted Q Iteration
[内容占位符]
### 2.3 Q Learning
[内容占位符]
### 2.4 DQN
[内容占位符]
### 2.5 Q Learning for Robotic Applications
[内容占位符]

## 3. Policy Learning
### 3.1 Policy Gradient
[内容占位符]
### 3.2 Policy Evaluation and Gradient
[内容占位符]
### 3.3 REINFORCE Algorithm
[内容占位符]
### 3.4 Understand Policy Gradient
[内容占位符]
### 3.5 Baseline
[内容占位符]
### 3.6 On Policy PG
[内容占位符]
### 3.7 Off Policy and Importance Sampling
[内容占位符]
### 3.8 DDPG
[内容占位符]
### 3.9 Robotics Applications with PG
[内容占位符]

## 4. Actor-Critic
### 4.1 Actor Critic
[内容占位符]
### 4.2 A3C: Asynchronous Advantage Actor Critic
[内容占位符]
### 4.3 GAE: General Advantage Estimation
[内容占位符]
### 4.4 Robotics Applications
[内容占位符]

## 5. Offline RL and Inverse RL
### 5.1 Recap
[内容占位符]
### 5.2 Offline RL
[内容占位符]
### 5.3 Robotic Applications
[内容占位符]

## 6. Other Methods and Discussions
### 6.1 Other Algorithms
[内容占位符]
### 6.2 Model-Based RL
[内容占位符]
### 6.3 Discussions
[内容占位符]
